#!/bin/bash
set -euo pipefail
export NCCL_BLOCKING_WAIT=1
export NCCL_TIMEOUT=10000  # è¶…æ—¶æ—¶é—´è®¾ç½®ä¸º1000ç§’ï¼Œé€‚åº”æ…¢è¿›ç¨‹
export FLASH_ATTENTION_FORCE_DISABLED=1


export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
NGPU=8

BASE_FILE="/fs-computility/llmit_d/shared/zhangchi/wjc/DPO/dataset/hh-train.jsonl"


DecoderLayer=Qwen3DecoderLayer
MODEL_NAME=qwen3-4b
EXP_NAME="$MODEL_NAME-dataset-hh-MAB-dpo-start-t0.7-0.5-ref-sft"
SAMPLE_NUM=1000
SAMPLE_TIMES=12
TOP_N=10000
MODEL_LOR="/fs-computility/llmit_d/shared/zhangchi/wjc/Qwen3-4B"
NUM_RESPONSE=3
REWARDMODEL="/fs-computility/llmit_d/shared/zhangchi/wjc/llama3-8b-reward"

BASE_WORKSPACE="/fs-computility/llmit_d/shared/zhangchi/wjc/DPO/MAB/$EXP_NAME"
mkdir -p $BASE_WORKSPACE
cp -r /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/turn/qwen3-4b-dpo-test1 $BASE_WORKSPACE
REF_MODEL_LOR="/fs-computility/llmit_d/shared/zhangchi/wjc/DPO/turn/qwen3-4b-sft-test1"
EXP_MODEL_LOR="$BASE_WORKSPACE/qwen3-4b-dpo-test1"


CLUSTER_DIR="/fs-computility/llmit_d/shared/zhangchi/wjc/DPO/MAB/k-means-clusters-hh"
CLUSTER_SCORE_JSON="$BASE_WORKSPACE/cluster_score.json"


# åˆå§‹åŒ–ç°‡åˆ†æ•°ï¼ˆæ‰€æœ‰ 100 ä¸ªç°‡åˆå§‹ score=1, count=1ï¼‰
python <<EOF
import json
scores = {i: 1.0 for i in range(100)}
counts = {i: 0 for i in range(100)}
json.dump({"scores": scores, "counts": counts}, open("$CLUSTER_SCORE_JSON", "w"))
EOF


for round in {1..3}; do
  echo "ğŸ Round $round: å¼€å§‹ MAB é‡‡æ · + 12 æ¬¡è¿­ä»£è¸©ç‚¹"

  WORK_DIR="$BASE_WORKSPACE/round-${round}"
  mkdir -p "$WORK_DIR"
  SELECTED_PRE_PATH="$WORK_DIR/selected-preferences.jsonl"
  > "$SELECTED_PRE_PATH"

  # æ¯è½®é‡‡æ · 12 æ¬¡ï¼Œæ¯æ¬¡ç”Ÿæˆ responseã€PPLã€æ›´æ–°åˆ†æ•°
  for iter in {1..12}; do
    SEED=$((RANDOM))
    echo "[$(date +'%F %T')] [Round $round][$iter/12] Stepâ€‘0: cluster_score åˆå§‹åŒ–"
    cp "$CLUSTER_SCORE_JSON" "$WORK_DIR/cluster_score_iter-${iter}-in.json"

    echo "[$(date +'%F %T')] [Step 1] é‡‡æ · 1000 ä¸ª prompt è¾“å…¥"
    python /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/MAB/mab_sample.py \
      --cluster_dir "$CLUSTER_DIR" \
      --cluster_score_json "$CLUSTER_SCORE_JSON" \
      --num_samples $SAMPLE_NUM \
      --random_seed $SEED \
      --output "$WORK_DIR/prompt_r${round}_i${iter}.jsonl"

    echo "[$(date +'%F %T')] [Step 2] ç”Ÿæˆ response"
    torchrun --nproc_per_node=$NGPU /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/data_cluster/prompt/torch_run_model.py \
      --input "$WORK_DIR/prompt_r${round}_i${iter}.jsonl" \
      --output "$WORK_DIR/resp_r${round}_i${iter}.jsonl" \
      --model "$EXP_MODEL_LOR" \
      --num-responses $NUM_RESPONSE \
      --temperature 0.7 \
      --top-p 0.9 \
      --max-prompt-tokens 256 \
      --max-length 1024 \
      --batch-size 8
    echo "[$(date +'%F %T')] [Step 2] ç”Ÿæˆresponseå®Œæˆ"

    echo "[$(date +'%F %T')] [Step 3] è®¡ç®— reward å¾—åˆ†"
    bash /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/Reward/run_reward_scoring.sh \
      $NGPU $REWARDMODEL "$WORK_DIR/resp_r${round}_i${iter}.jsonl" \
      "$WORK_DIR/reward_r${round}_i${iter}.jsonl"

    echo "[$(date +'%F %T')] [Step 4] è®¡ç®— PPL å’Œ TokenCount"
    torchrun --nproc_per_node=$NGPU /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/data_select/PPL-NEW.py \
      --model_name "$EXP_MODEL_LOR" \
      --input_path "$WORK_DIR/reward_r${round}_i${iter}.jsonl" \
      --output_path "$WORK_DIR/data_pre_r${round}_i${iter}.jsonl" \
      --batch_size 64 \
      --max_length 1200
    echo "[$(date +'%F %T')] [Step 4] è®¡ç®—PPLå’ŒTokenå®Œæˆ"

    echo "[$(date +'%F %T')] [Step 5] æ„å»ºåå¥½å¯¹ & æ›´æ–°ç°‡å¾—åˆ†"
    python /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/MAB/update_cluster_score.py \
      --data_path "$WORK_DIR/data_pre_r${round}_i${iter}.jsonl" \
      --cluster_score_json_in "$CLUSTER_SCORE_JSON" \
      --cluster_score_json_out "$CLUSTER_SCORE_JSON" \
      --selected_out "$SELECTED_PRE_PATH"

    echo "[$(date +'%F %T')] [Step 6] å®Œæˆç¬¬ ${iter} æ¬¡é‡‡æ ·"

  done  # iter 12 æ¬¡

  echo "âœ… Round $round å®Œæˆå…± 12â€¯000 æ¡åå¥½å¯¹é‡‡æ ·ï¼Œå¼€å§‹è®­ç»ƒæ¨¡å‹"

  # ï¼ˆé€‰é¡¹1ï¼‰è®­ç»ƒå‰è¿˜å¯ä»¥åšä¸€æ¬¡éšæœºæ•°æ®é€‰æ‹©æˆ–æ¸…æ´—
  # è¿™é‡Œæˆ‘ä»¬å‡è®¾ SELECTED_PRE_PATH å·²ç»ç´¯ç§¯äº† 12â€¯000 æ¡åå¥½å¯¹
  echo "[$(date +'%F %T')] [Step 7] æ•°æ®é€‰æ‹©: è¾“å…¥=$SELECTED_PRE_PATH è¾“å‡º=$WORK_DIR/train.jsonl"
    python /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/data_select/dataselect-random.py \
    --input "$SELECTED_PRE_PATH" \
    --output "$WORK_DIR/train.jsonl" \
    --top_n $TOP_N \
    --score_gap 3
    echo "[$(date +'%F %T')] [Step 7] æ•°æ®é€‰æ‹©å®Œæˆ"

  # è¿›å…¥DPOä¸»ç›®å½•
  DPO_LOG=$WORK_DIR/$EXP_NAME-dpo.log

  cd /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/direct-preference-optimization-main
  echo "[$(date +'%F %T')] [Step ] è¿›å…¥DPOä¸»ç›®å½•:"
  mkdir -p $WORK_DIR/.cache


  # DPOè®­ç»ƒ
  echo "[$(date +'%F %T')] [Step 10] å¼€å§‹DPOè®­ç»ƒ: æ—¥å¿—è¾“å‡ºåˆ° $DPO_LOG"
  python ref-train.py \
  local_dirs="['$WORK_DIR/.cache']" \
  model=$MODEL_NAME \
  model.name_or_path=$EXP_MODEL_LOR \
  model.reference_name_or_path=$REF_MODEL_LOR \
  model.tokenizer_name_or_path=$EXP_MODEL_LOR \
  model.block_name=$DecoderLayer \
  model.policy_dtype=bfloat16 \
  model.reference_dtype=bfloat16 \
  trainer=FSDPTrainer \
  datasets=["$WORK_DIR/train.jsonl"] \
  loss=dpo \
  loss.beta=0.1 \
  exp_name=$EXP_NAME-$round-dpo \
  gradient_accumulation_steps=16 \
  lr=5e-6 \
  batch_size=128 \
  n_epochs=1 \
  eval_batch_size=8 \
  sample_during_eval=false \
  model.fsdp_policy_mp=bfloat16 \
  > $DPO_LOG 2>&1
  echo "[$(date +'%F %T')] ğŸ‰ DPOè®­ç»ƒå®Œæˆ"

  DPO_PT=$WORK_DIR/.cache/root/$EXP_NAME-$round-dpo/LATEST/policy.pt
  DPO_SAVE=$WORK_DIR/$EXP_NAME-$round-dpo

  # æƒé‡è½¬æ¢
  echo "[$(date +'%F %T')] [Step 11/$round] DPOæƒé‡è½¬æ¢: è¾“å‡ºåˆ° $DPO_SAVE"
  python /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/turn/turn_to.py \
    --base_model $MODEL_LOR \
    --policy_ckpt $DPO_PT \
    --out_dir $DPO_SAVE
  echo "[$(date +'%F %T')] [Step 11/$round] DPOæƒé‡è½¬æ¢å®Œæˆ"

  # æƒé‡æ‹·è´ï¼ˆå…ˆåˆ å†æ‹·ï¼Œä¿è¯å®Œå…¨è¦†ç›–ï¼‰
  echo "[$(date +'%F %T')] [Step 12/$round] æ‹·è´æƒé‡åˆ° EXP_MODEL_LOR: $EXP_MODEL_LOR"
  rm -rf $EXP_MODEL_LOR
  cp -r $DPO_SAVE $EXP_MODEL_LOR
  echo "[$(date +'%F %T')] [Step 12/$round] æƒé‡æ‹·è´å®Œæˆ"

  echo "[$(date +'%F %T')] [Step END/$round] ç¬¬ $round è½®å®éªŒå…¨éƒ¨å®Œæˆ"

done

echo "ğŸ å…¨éƒ¨ä¸‰è½®å®Œæˆï¼Œæ€»å…±ç”Ÿæˆ ${EXP_NAME}â€round[1â€‘3]"
echo "[$(date +'%F %T')]"
