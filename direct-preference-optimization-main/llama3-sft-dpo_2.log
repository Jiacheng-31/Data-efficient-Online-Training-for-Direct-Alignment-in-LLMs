WARNING: eval_every must be divisible by batch_size
Setting eval_every to 19968
no FSDP port specified; using open port for FSDP: 35495
seed: 0
exp_name: llama3-8b-sftdpo-warmup-hh-helpful-dpo
batch_size: 128
eval_batch_size: 16
debug: false
fsdp_port: 35495
datasets:
- /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/dataset/hh-help-10000.jsonl
wandb:
  enabled: true
  entity: null
  project: direct-preference-optimization
local_dirs:
- /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/direct-preference-optimization-main/.cache
sample_during_eval: false
n_eval_model_samples: 16
do_first_eval: true
local_run_dir: /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/direct-preference-optimization-main/.cache/root/llama3-8b-sftdpo-warmup-hh-helpful-dpo
lr: 5.0e-06
gradient_accumulation_steps: 16
max_grad_norm: 10.0
max_length: 2048
max_prompt_length: 512
n_epochs: 1
n_examples: null
n_eval_examples: 256
trainer: FSDPTrainer
optimizer: RMSprop
warmup_steps: 150
activation_checkpointing: false
eval_every: 19968
minimum_log_interval_secs: 1.0
model:
  name_or_path: /fs-computility/llmit_d/shared/zhangchi/wjc/Llama3-8B-Base
  tokenizer_name_or_path: /fs-computility/llmit_d/shared/zhangchi/wjc/Llama3-8B-Base
  archive: /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/direct-preference-optimization-main/.cache/root/llama3-8b-sftdpo-warmup-hh-helpful-sft/LATEST/policy.pt
  block_name: LlamaDecoderLayer
  policy_dtype: float32
  fsdp_policy_mp: bfloat16
  reference_dtype: float16
loss:
  name: dpo
  beta: 0.1
  label_smoothing: 0
  reference_free: false

================================================================================
Writing to t-20250727224157-jr2mh-worker-0:/fs-computility/llmit_d/shared/zhangchi/wjc/DPO/direct-preference-optimization-main/.cache/root/llama3-8b-sftdpo-warmup-hh-helpful-dpo
================================================================================
building policy
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.36it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.40it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.42it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  2.05it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.75it/s]
building reference model
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.87it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.86it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.87it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.69it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.31it/s]
loading pre-trained weights at step 9984 from /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/direct-preference-optimization-main/.cache/root/llama3-8b-sftdpo-warmup-hh-helpful-sft/LATEST/policy.pt with metrics {}
loaded pre-trained weights
starting 8 processes for FSDP training
setting RLIMIT_NOFILE soft limit to 1048576 from 1048576
[rank1]:[W727 15:00:49.983283856 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W727 15:00:54.845765380 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W727 15:00:58.684482562 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank4]:[W727 15:01:01.413719584 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank5]:[W727 15:01:05.220413773 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank6]:[W727 15:01:10.971512722 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank7]:[W727 15:01:14.409777952 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank0]:[W727 15:01:14.518985539 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
t-20250727224157-jr2mh-worker-0:6638:6638 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:6638:6638 [0] NCCL INFO Bootstrap : Using eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:6638:6638 [0] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:6638:6638 [0] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
t-20250727224157-jr2mh-worker-0:6638:6638 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:6638:6638 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
t-20250727224157-jr2mh-worker-0:6638:6638 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.21.5+cuda12.4
0 initializing distributed
Creating trainer on process 0 with world size 8
Loading tokenizer /fs-computility/llmit_d/shared/zhangchi/wjc/Llama3-8B-Base
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 696.8 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 0% | 内存使用 14268.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 0% | 内存使用 14268.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 0% | 内存使用 14268.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 0% | 内存使用 14268.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 0% | 内存使用 14268.2 MB / 81920.0 MB
Loaded train data iterator
[GPU Monitor] GPU 6: 利用率 27% | 内存使用 5540.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 0% | 内存使用 1114.2 MB / 81920.0 MB
FINISHED 256 EXAMPLES on test split
Loaded 16 eval batches of size 16
Sharding policy with FSDP...
Sharding reference model with FSDP...
Loaded model on rank 0
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 14702.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 0% | 内存使用 14798.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 0% | 内存使用 14798.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 0% | 内存使用 14798.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 0% | 内存使用 14798.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 0% | 内存使用 14798.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 0% | 内存使用 14798.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 0% | 内存使用 14702.2 MB / 81920.0 MB
Using RMSprop optimizer
=== Running evaluation after 0 train examples ===
Computing eval metrics:   0%|          | 0/16 [00:00<?, ?it/s]Computing eval metrics:   6%|▋         | 1/16 [00:02<00:34,  2.32s/it]Computing eval metrics:  12%|█▎        | 2/16 [00:02<00:16,  1.18s/it]Computing eval metrics:  19%|█▉        | 3/16 [00:03<00:10,  1.28it/s]Computing eval metrics:  25%|██▌       | 4/16 [00:03<00:10,  1.18it/s]Computing eval metrics:  31%|███▏      | 5/16 [00:04<00:07,  1.44it/s]Computing eval metrics:  38%|███▊      | 6/16 [00:04<00:05,  1.69it/s]Computing eval metrics:  44%|████▍     | 7/16 [00:05<00:05,  1.78it/s]Computing eval metrics:  50%|█████     | 8/16 [00:05<00:04,  1.99it/s]Computing eval metrics:  56%|█████▋    | 9/16 [00:06<00:03,  2.13it/s]Computing eval metrics:  62%|██████▎   | 10/16 [00:06<00:02,  2.15it/s]Computing eval metrics:  69%|██████▉   | 11/16 [00:06<00:02,  2.23it/s]Computing eval metrics:  75%|███████▌  | 12/16 [00:07<00:01,  2.22it/s]Computing eval metrics:  81%|████████▏ | 13/16 [00:07<00:01,  2.24it/s]Computing eval metrics:  88%|████████▊ | 14/16 [00:08<00:00,  2.42it/s]Computing eval metrics:  94%|█████████▍| 15/16 [00:08<00:00,  2.35it/s]Computing eval metrics: 100%|██████████| 16/16 [00:09<00:00,  1.94it/s]Computing eval metrics: 100%|██████████| 16/16 [00:09<00:00,  1.72it/s]
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:863: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:863: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:863: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:863: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:863: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:863: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:863: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/DPO/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:863: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
1 initializing distributed
Creating trainer on process 1 with world size 8
3 initializing distributed
Creating trainer on process 3 with world size 8
t-20250727224157-jr2mh-worker-0:6716:6716 [1] NCCL INFO cudaDriverVersion 12040
t-20250727224157-jr2mh-worker-0:6716:6716 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:6716:6716 [1] NCCL INFO Bootstrap : Using eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:6716:6716 [1] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:6716:6716 [1] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
t-20250727224157-jr2mh-worker-0:6716:6716 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:6716:6716 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
t-20250727224157-jr2mh-worker-0:6716:6716 [1] NCCL INFO Comm config Blocking set to 1
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO P2P plugin IBext
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_2:1/RoCE [2]mlx5_3:1/RoCE [3]mlx5_4:1/RoCE [RO]; OOB eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Using non-device net plugin version 0
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Using network IBext
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO ncclCommInitRank comm 0xe4ce190 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 46000 commId 0xfc447bdf9e87bd95 - Init START
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO NVLS multicast support is not available on dev 1
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO comm 0xe4ce190 rank 1 nRanks 8 nNodes 1 localRanks 8 localRank 1 MNNVL 0
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO P2P Chunksize set to 524288
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 08/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 09/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 11/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 13/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 14/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 15/0 : 1[1] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Connected all rings
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO Connected all trees
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO 16 coll channels, 16 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.
t-20250727224157-jr2mh-worker-0:6716:7882 [1] NCCL INFO ncclCommInitRank comm 0xe4ce190 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 46000 commId 0xfc447bdf9e87bd95 - Init COMPLETE
6 initializing distributed
Creating trainer on process 6 with world size 8
7 initializing distributed
Creating trainer on process 7 with world size 8
t-20250727224157-jr2mh-worker-0:7411:7411 [6] NCCL INFO cudaDriverVersion 12040
t-20250727224157-jr2mh-worker-0:7411:7411 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:7411:7411 [6] NCCL INFO Bootstrap : Using eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:7411:7411 [6] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:7411:7411 [6] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
t-20250727224157-jr2mh-worker-0:7411:7411 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:7411:7411 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
t-20250727224157-jr2mh-worker-0:7411:7411 [6] NCCL INFO Comm config Blocking set to 1
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO P2P plugin IBext
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_2:1/RoCE [2]mlx5_3:1/RoCE [3]mlx5_4:1/RoCE [RO]; OOB eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Using non-device net plugin version 0
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Using network IBext
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO ncclCommInitRank comm 0x117657d0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId c1000 commId 0xfc447bdf9e87bd95 - Init START
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,00000000,ffffffff,00000000
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO NVLS multicast support is not available on dev 6
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO comm 0x117657d0 rank 6 nRanks 8 nNodes 1 localRanks 8 localRank 6 MNNVL 0
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO P2P Chunksize set to 524288
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 00/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 01/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 02/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 03/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 04/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 05/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 06/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 07/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 08/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 09/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 10/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 11/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 12/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 13/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 14/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 15/0 : 6[6] -> 7[7] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Connected all rings
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 00/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 01/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 02/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 03/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 04/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 05/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 06/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 07/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 08/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 09/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 10/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 11/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 12/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 13/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 14/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Channel 15/0 : 6[6] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO Connected all trees
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO 16 coll channels, 16 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.
t-20250727224157-jr2mh-worker-0:7411:7884 [6] NCCL INFO ncclCommInitRank comm 0x117657d0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId c1000 commId 0xfc447bdf9e87bd95 - Init COMPLETE
2 initializing distributed
Creating trainer on process 2 with world size 8
4 initializing distributed
Creating trainer on process 4 with world size 8
t-20250727224157-jr2mh-worker-0:6802:6802 [2] NCCL INFO cudaDriverVersion 12040
t-20250727224157-jr2mh-worker-0:6802:6802 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:6802:6802 [2] NCCL INFO Bootstrap : Using eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:6802:6802 [2] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:6802:6802 [2] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
t-20250727224157-jr2mh-worker-0:6802:6802 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:6802:6802 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
t-20250727224157-jr2mh-worker-0:6802:6802 [2] NCCL INFO Comm config Blocking set to 1
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO P2P plugin IBext
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_2:1/RoCE [2]mlx5_3:1/RoCE [3]mlx5_4:1/RoCE [RO]; OOB eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Using non-device net plugin version 0
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Using network IBext
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO ncclCommInitRank comm 0xe8cd240 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 65000 commId 0xfc447bdf9e87bd95 - Init START
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO NVLS multicast support is not available on dev 2
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO comm 0xe8cd240 rank 2 nRanks 8 nNodes 1 localRanks 8 localRank 2 MNNVL 0
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO P2P Chunksize set to 524288
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 11/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 13/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 15/0 : 2[2] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Connected all rings
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 08/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 10/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 12/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 13/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 14/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO Connected all trees
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO 16 coll channels, 16 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.
t-20250727224157-jr2mh-worker-0:6802:7883 [2] NCCL INFO ncclCommInitRank comm 0xe8cd240 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 65000 commId 0xfc447bdf9e87bd95 - Init COMPLETE
5 initializing distributed
Creating trainer on process 5 with world size 8
Eval after 0 examples: {'rewards_eval/chosen': '0.062701', 'rewards_eval/rejected': '0.066421', 'rewards_eval/accuracies': '0.5', 'rewards_eval/margins': '-0.0037197', 'logps_eval/rejected': '-115.63', 'logps_eval/chosen': '-119.5', 'loss/eval': '0.69842'}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 48488.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 48448.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 48840.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 48342.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 48232.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 48748.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 48878.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 48644.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 68402.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 68444.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 68498.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 68444.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 68498.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 68498.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 68444.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 68348.2 MB / 81920.0 MB
Train stats after 128 examples: {'rewards_train/chosen': '0.071576', 'rewards_train/rejected': '0.074061', 'rewards_train/accuracies': '0.51562', 'rewards_train/margins': '-0.0024852', 'logps_train/rejected': '-127.04', 'logps_train/chosen': '-124.88', 'loss/train': '0.69818', 'examples_per_second': '6.3845', 'grad_norm': '13.336', 'counters/examples': 128, 'counters/updates': 1}
[GPU Monitor] GPU 0: 利用率 50% | 内存使用 68404.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 73% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 45% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 70% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 90% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 34% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 47% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 31% | 内存使用 68350.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 68404.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 68350.2 MB / 81920.0 MB
Train stats after 256 examples: {'rewards_train/chosen': '0.061178', 'rewards_train/rejected': '0.057319', 'rewards_train/accuracies': '0.49219', 'rewards_train/margins': '0.0038586', 'logps_train/rejected': '-104.23', 'logps_train/chosen': '-114.04', 'loss/train': '0.69371', 'examples_per_second': '9.0738', 'grad_norm': '13.462', 'counters/examples': 256, 'counters/updates': 2}
[GPU Monitor] GPU 0: 利用率 98% | 内存使用 68404.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 98% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 68350.2 MB / 81920.0 MB
Train stats after 384 examples: {'rewards_train/chosen': '0.053026', 'rewards_train/rejected': '0.090447', 'rewards_train/accuracies': '0.40625', 'rewards_train/margins': '-0.037421', 'logps_train/rejected': '-120.44', 'logps_train/chosen': '-126.16', 'loss/train': '0.71568', 'examples_per_second': '9.6023', 'grad_norm': '13.462', 'counters/examples': 384, 'counters/updates': 3}
[GPU Monitor] GPU 0: 利用率 42% | 内存使用 68404.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 61% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 0% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 25% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 12% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 19% | 内存使用 68500.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 85% | 内存使用 68446.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 5% | 内存使用 68350.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 69688.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 69730.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 69784.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 69730.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 69784.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 69784.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 69730.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 69634.2 MB / 81920.0 MB
Train stats after 512 examples: {'rewards_train/chosen': '0.043176', 'rewards_train/rejected': '0.060876', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.0177', 'logps_train/rejected': '-122.53', 'logps_train/chosen': '-138.36', 'loss/train': '0.70432', 'examples_per_second': '6.9202', 'grad_norm': '13.707', 'counters/examples': 512, 'counters/updates': 4}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 80420.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 80462.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 80516.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 80462.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 80516.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 80516.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 80462.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 80366.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 98% | 内存使用 78456.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 78456.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 78510.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 78606.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 78456.2 MB / 81920.0 MB
Train stats after 640 examples: {'rewards_train/chosen': '0.047934', 'rewards_train/rejected': '0.055071', 'rewards_train/accuracies': '0.52344', 'rewards_train/margins': '-0.0071374', 'logps_train/rejected': '-106.4', 'logps_train/chosen': '-119.53', 'loss/train': '0.69981', 'examples_per_second': '4.9586', 'grad_norm': '13.373', 'counters/examples': 640, 'counters/updates': 5}
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 78510.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 96% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 96% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 78606.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 78456.2 MB / 81920.0 MB
Train stats after 768 examples: {'rewards_train/chosen': '0.0097701', 'rewards_train/rejected': '0.037517', 'rewards_train/accuracies': '0.46094', 'rewards_train/margins': '-0.027747', 'logps_train/rejected': '-103', 'logps_train/chosen': '-103.3', 'loss/train': '0.71043', 'examples_per_second': '9.1915', 'grad_norm': '12.31', 'counters/examples': 768, 'counters/updates': 6}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 78510.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 65% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 95% | 内存使用 78606.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 90% | 内存使用 78456.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 98% | 内存使用 78510.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 96% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 78552.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 78606.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 78456.2 MB / 81920.0 MB
Train stats after 896 examples: {'rewards_train/chosen': '0.0027994', 'rewards_train/rejected': '0.021212', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '-0.018413', 'logps_train/rejected': '-121.89', 'logps_train/chosen': '-97.223', 'loss/train': '0.70543', 'examples_per_second': '8.3303', 'grad_norm': '12.941', 'counters/examples': 896, 'counters/updates': 7}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 78928.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79024.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79024.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 78928.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 78928.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79024.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79024.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 78928.2 MB / 81920.0 MB
Train stats after 1024 examples: {'rewards_train/chosen': '0.0079449', 'rewards_train/rejected': '0.022646', 'rewards_train/accuracies': '0.47656', 'rewards_train/margins': '-0.014701', 'logps_train/rejected': '-128.6', 'logps_train/chosen': '-129.65', 'loss/train': '0.70602', 'examples_per_second': '8.9918', 'grad_norm': '15.163', 'counters/examples': 1024, 'counters/updates': 8}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 78928.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79024.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79024.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 78928.2 MB / 81920.0 MB
Train stats after 1152 examples: {'rewards_train/chosen': '-0.030742', 'rewards_train/rejected': '0.0013424', 'rewards_train/accuracies': '0.4375', 'rewards_train/margins': '-0.032085', 'logps_train/rejected': '-86.508', 'logps_train/chosen': '-100.52', 'loss/train': '0.71572', 'examples_per_second': '7.7917', 'grad_norm': '12.975', 'counters/examples': 1152, 'counters/updates': 9}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 78928.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 78970.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79024.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 98% | 内存使用 79024.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 78928.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 1280 examples: {'rewards_train/chosen': '-0.025375', 'rewards_train/rejected': '-0.002513', 'rewards_train/accuracies': '0.49219', 'rewards_train/margins': '-0.022862', 'logps_train/rejected': '-109.12', 'logps_train/chosen': '-90.223', 'loss/train': '0.71052', 'examples_per_second': '10.164', 'grad_norm': '13.179', 'counters/examples': 1280, 'counters/updates': 10}
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 1408 examples: {'rewards_train/chosen': '-0.036899', 'rewards_train/rejected': '-0.032994', 'rewards_train/accuracies': '0.57812', 'rewards_train/margins': '-0.003905', 'logps_train/rejected': '-143.77', 'logps_train/chosen': '-122.2', 'loss/train': '0.7026', 'examples_per_second': '9.0779', 'grad_norm': '14.97', 'counters/examples': 1408, 'counters/updates': 11}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 1536 examples: {'rewards_train/chosen': '-0.08153', 'rewards_train/rejected': '-0.033949', 'rewards_train/accuracies': '0.42188', 'rewards_train/margins': '-0.04758', 'logps_train/rejected': '-132.2', 'logps_train/chosen': '-121.51', 'loss/train': '0.73521', 'examples_per_second': '8.7407', 'grad_norm': '15.723', 'counters/examples': 1536, 'counters/updates': 12}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 98% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 1664 examples: {'rewards_train/chosen': '-0.086273', 'rewards_train/rejected': '-0.078821', 'rewards_train/accuracies': '0.48438', 'rewards_train/margins': '-0.0074529', 'logps_train/rejected': '-92.91', 'logps_train/chosen': '-93.146', 'loss/train': '0.70976', 'examples_per_second': '8.9883', 'grad_norm': '13.157', 'counters/examples': 1664, 'counters/updates': 13}
[GPU Monitor] GPU 0: 利用率 98% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 98% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 1792 examples: {'rewards_train/chosen': '-0.11937', 'rewards_train/rejected': '-0.1008', 'rewards_train/accuracies': '0.46094', 'rewards_train/margins': '-0.018574', 'logps_train/rejected': '-117.88', 'logps_train/chosen': '-121.12', 'loss/train': '0.72033', 'examples_per_second': '7.7975', 'grad_norm': '14.484', 'counters/examples': 1792, 'counters/updates': 14}
[GPU Monitor] GPU 0: 利用率 96% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 98% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 96% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 96% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 1920 examples: {'rewards_train/chosen': '-0.096739', 'rewards_train/rejected': '-0.1237', 'rewards_train/accuracies': '0.53125', 'rewards_train/margins': '0.026959', 'logps_train/rejected': '-111.77', 'logps_train/chosen': '-106.17', 'loss/train': '0.6929', 'examples_per_second': '10.647', 'grad_norm': '14.092', 'counters/examples': 1920, 'counters/updates': 15}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79388.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 2048 examples: {'rewards_train/chosen': '-0.12283', 'rewards_train/rejected': '-0.17981', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.056972', 'logps_train/rejected': '-112.55', 'logps_train/chosen': '-105.12', 'loss/train': '0.68496', 'examples_per_second': '6.4058', 'grad_norm': '14.569', 'counters/examples': 2048, 'counters/updates': 16}
[GPU Monitor] GPU 0: 利用率 98% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 98% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 98% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 2176 examples: {'rewards_train/chosen': '-0.16886', 'rewards_train/rejected': '-0.199', 'rewards_train/accuracies': '0.49219', 'rewards_train/margins': '0.030141', 'logps_train/rejected': '-124.18', 'logps_train/chosen': '-122.49', 'loss/train': '0.70747', 'examples_per_second': '7.3488', 'grad_norm': '15.43', 'counters/examples': 2176, 'counters/updates': 17}
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 2304 examples: {'rewards_train/chosen': '-0.23318', 'rewards_train/rejected': '-0.28549', 'rewards_train/accuracies': '0.59375', 'rewards_train/margins': '0.052313', 'logps_train/rejected': '-113.2', 'logps_train/chosen': '-109.44', 'loss/train': '0.68851', 'examples_per_second': '10.128', 'grad_norm': '14.38', 'counters/examples': 2304, 'counters/updates': 18}
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 0% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 0% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 0% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 0% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 0% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 0% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 0% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 2432 examples: {'rewards_train/chosen': '-0.27266', 'rewards_train/rejected': '-0.27284', 'rewards_train/accuracies': '0.55469', 'rewards_train/margins': '0.00017931', 'logps_train/rejected': '-103.22', 'logps_train/chosen': '-115.89', 'loss/train': '0.73133', 'examples_per_second': '5.1034', 'grad_norm': '16.137', 'counters/examples': 2432, 'counters/updates': 19}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 2560 examples: {'rewards_train/chosen': '-0.19256', 'rewards_train/rejected': '-0.21204', 'rewards_train/accuracies': '0.53906', 'rewards_train/margins': '0.019479', 'logps_train/rejected': '-104.44', 'logps_train/chosen': '-91.005', 'loss/train': '0.7101', 'examples_per_second': '7.6756', 'grad_norm': '14.02', 'counters/examples': 2560, 'counters/updates': 20}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 2688 examples: {'rewards_train/chosen': '-0.22355', 'rewards_train/rejected': '-0.27153', 'rewards_train/accuracies': '0.60938', 'rewards_train/margins': '0.047988', 'logps_train/rejected': '-112.29', 'logps_train/chosen': '-113.15', 'loss/train': '0.69123', 'examples_per_second': '10.575', 'grad_norm': '15.045', 'counters/examples': 2688, 'counters/updates': 21}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 2816 examples: {'rewards_train/chosen': '-0.16045', 'rewards_train/rejected': '-0.37282', 'rewards_train/accuracies': '0.61719', 'rewards_train/margins': '0.21237', 'logps_train/rejected': '-129.48', 'logps_train/chosen': '-110.02', 'loss/train': '0.62649', 'examples_per_second': '9.0768', 'grad_norm': '14.211', 'counters/examples': 2816, 'counters/updates': 22}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 2944 examples: {'rewards_train/chosen': '-0.3868', 'rewards_train/rejected': '-0.56909', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.1823', 'logps_train/rejected': '-126.14', 'logps_train/chosen': '-114.83', 'loss/train': '0.65461', 'examples_per_second': '11.808', 'grad_norm': '15.675', 'counters/examples': 2944, 'counters/updates': 23}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 98% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 3072 examples: {'rewards_train/chosen': '-0.52669', 'rewards_train/rejected': '-0.68857', 'rewards_train/accuracies': '0.60156', 'rewards_train/margins': '0.16189', 'logps_train/rejected': '-120.54', 'logps_train/chosen': '-117.75', 'loss/train': '0.66718', 'examples_per_second': '11.389', 'grad_norm': '16.316', 'counters/examples': 3072, 'counters/updates': 24}
[GPU Monitor] GPU 0: 利用率 96% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 96% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 96% | 内存使用 79442.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 96% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 96% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 3200 examples: {'rewards_train/chosen': '-0.52962', 'rewards_train/rejected': '-0.63714', 'rewards_train/accuracies': '0.61719', 'rewards_train/margins': '0.10753', 'logps_train/rejected': '-118.35', 'logps_train/chosen': '-106.9', 'loss/train': '0.68914', 'examples_per_second': '8.7049', 'grad_norm': '16.344', 'counters/examples': 3200, 'counters/updates': 25}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 3328 examples: {'rewards_train/chosen': '-0.54953', 'rewards_train/rejected': '-0.73906', 'rewards_train/accuracies': '0.5625', 'rewards_train/margins': '0.18954', 'logps_train/rejected': '-118.62', 'logps_train/chosen': '-110.29', 'loss/train': '0.65678', 'examples_per_second': '11.454', 'grad_norm': '15.477', 'counters/examples': 3328, 'counters/updates': 26}
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 96% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 3456 examples: {'rewards_train/chosen': '-0.59461', 'rewards_train/rejected': '-0.83068', 'rewards_train/accuracies': '0.66406', 'rewards_train/margins': '0.23607', 'logps_train/rejected': '-144.43', 'logps_train/chosen': '-131.91', 'loss/train': '0.63931', 'examples_per_second': '6.7413', 'grad_norm': '18.266', 'counters/examples': 3456, 'counters/updates': 27}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 3584 examples: {'rewards_train/chosen': '-0.45516', 'rewards_train/rejected': '-0.75983', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.30467', 'logps_train/rejected': '-127.21', 'logps_train/chosen': '-118.92', 'loss/train': '0.63461', 'examples_per_second': '10.529', 'grad_norm': '18.132', 'counters/examples': 3584, 'counters/updates': 28}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 3712 examples: {'rewards_train/chosen': '-0.74158', 'rewards_train/rejected': '-0.99', 'rewards_train/accuracies': '0.60156', 'rewards_train/margins': '0.24842', 'logps_train/rejected': '-138.57', 'logps_train/chosen': '-121.82', 'loss/train': '0.64316', 'examples_per_second': '8.6679', 'grad_norm': '16.147', 'counters/examples': 3712, 'counters/updates': 29}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 3840 examples: {'rewards_train/chosen': '-0.75945', 'rewards_train/rejected': '-1.0893', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.32982', 'logps_train/rejected': '-139.23', 'logps_train/chosen': '-127.16', 'loss/train': '0.63431', 'examples_per_second': '7.3084', 'grad_norm': '17.558', 'counters/examples': 3840, 'counters/updates': 30}
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 0% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 0% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 0% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 0% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 0% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 0% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 0% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 3968 examples: {'rewards_train/chosen': '-0.58283', 'rewards_train/rejected': '-0.93182', 'rewards_train/accuracies': '0.66406', 'rewards_train/margins': '0.34899', 'logps_train/rejected': '-120.79', 'logps_train/chosen': '-106.88', 'loss/train': '0.59082', 'examples_per_second': '7.5671', 'grad_norm': '14.972', 'counters/examples': 3968, 'counters/updates': 31}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 96% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 96% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 4096 examples: {'rewards_train/chosen': '-0.89611', 'rewards_train/rejected': '-1.2533', 'rewards_train/accuracies': '0.69531', 'rewards_train/margins': '0.35721', 'logps_train/rejected': '-137.54', 'logps_train/chosen': '-111.44', 'loss/train': '0.61832', 'examples_per_second': '10.698', 'grad_norm': '16.058', 'counters/examples': 4096, 'counters/updates': 32}
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 3% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 13% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 37% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 24% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 62% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 16% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 30% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 98% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 4224 examples: {'rewards_train/chosen': '-0.97388', 'rewards_train/rejected': '-1.3066', 'rewards_train/accuracies': '0.60156', 'rewards_train/margins': '0.33267', 'logps_train/rejected': '-125.07', 'logps_train/chosen': '-116.97', 'loss/train': '0.66143', 'examples_per_second': '10.475', 'grad_norm': '18.191', 'counters/examples': 4224, 'counters/updates': 33}
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 96% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 4352 examples: {'rewards_train/chosen': '-0.54772', 'rewards_train/rejected': '-0.92572', 'rewards_train/accuracies': '0.75781', 'rewards_train/margins': '0.378', 'logps_train/rejected': '-118.92', 'logps_train/chosen': '-106.47', 'loss/train': '0.57515', 'examples_per_second': '9.6133', 'grad_norm': '15.316', 'counters/examples': 4352, 'counters/updates': 34}
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 79346.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 4480 examples: {'rewards_train/chosen': '-0.98299', 'rewards_train/rejected': '-1.3698', 'rewards_train/accuracies': '0.58594', 'rewards_train/margins': '0.38682', 'logps_train/rejected': '-145.65', 'logps_train/chosen': '-148.69', 'loss/train': '0.63128', 'examples_per_second': '5.6039', 'grad_norm': '20.258', 'counters/examples': 4480, 'counters/updates': 35}
[GPU Monitor] GPU 0: 利用率 96% | 内存使用 79454.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 79550.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 96% | 内存使用 79346.2 MB / 81920.0 MB
Train stats after 4608 examples: {'rewards_train/chosen': '-0.75165', 'rewards_train/rejected': '-1.1843', 'rewards_train/accuracies': '0.67188', 'rewards_train/margins': '0.43269', 'logps_train/rejected': '-118.64', 'logps_train/chosen': '-122.9', 'loss/train': '0.58949', 'examples_per_second': '8.2692', 'grad_norm': '17.087', 'counters/examples': 4608, 'counters/updates': 36}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81338.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81338.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 4736 examples: {'rewards_train/chosen': '-0.73294', 'rewards_train/rejected': '-1.2405', 'rewards_train/accuracies': '0.72656', 'rewards_train/margins': '0.50758', 'logps_train/rejected': '-126.46', 'logps_train/chosen': '-108.29', 'loss/train': '0.54846', 'examples_per_second': '4.8388', 'grad_norm': '16.062', 'counters/examples': 4736, 'counters/updates': 37}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 96% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 96% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 96% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 96% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 4864 examples: {'rewards_train/chosen': '-0.99283', 'rewards_train/rejected': '-1.3903', 'rewards_train/accuracies': '0.64844', 'rewards_train/margins': '0.39743', 'logps_train/rejected': '-135.39', 'logps_train/chosen': '-116.47', 'loss/train': '0.59546', 'examples_per_second': '7.4205', 'grad_norm': '15.978', 'counters/examples': 4864, 'counters/updates': 38}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 4992 examples: {'rewards_train/chosen': '-1.4325', 'rewards_train/rejected': '-1.9022', 'rewards_train/accuracies': '0.64844', 'rewards_train/margins': '0.46965', 'logps_train/rejected': '-132.58', 'logps_train/chosen': '-146.12', 'loss/train': '0.65027', 'examples_per_second': '8.7515', 'grad_norm': '23.68', 'counters/examples': 4992, 'counters/updates': 39}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 5120 examples: {'rewards_train/chosen': '-0.67144', 'rewards_train/rejected': '-1.1958', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.5244', 'logps_train/rejected': '-116.87', 'logps_train/chosen': '-106.99', 'loss/train': '0.54738', 'examples_per_second': '8.8096', 'grad_norm': '14.652', 'counters/examples': 5120, 'counters/updates': 40}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 98% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 5248 examples: {'rewards_train/chosen': '-0.80391', 'rewards_train/rejected': '-1.3325', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.52861', 'logps_train/rejected': '-127.24', 'logps_train/chosen': '-128.24', 'loss/train': '0.58055', 'examples_per_second': '10.098', 'grad_norm': '16.349', 'counters/examples': 5248, 'counters/updates': 41}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 5376 examples: {'rewards_train/chosen': '-0.75549', 'rewards_train/rejected': '-1.2974', 'rewards_train/accuracies': '0.72656', 'rewards_train/margins': '0.54193', 'logps_train/rejected': '-130.44', 'logps_train/chosen': '-106.44', 'loss/train': '0.5621', 'examples_per_second': '7.6184', 'grad_norm': '14.609', 'counters/examples': 5376, 'counters/updates': 42}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 98% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 5504 examples: {'rewards_train/chosen': '-0.87151', 'rewards_train/rejected': '-1.4593', 'rewards_train/accuracies': '0.76562', 'rewards_train/margins': '0.58779', 'logps_train/rejected': '-98.84', 'logps_train/chosen': '-98.441', 'loss/train': '0.52208', 'examples_per_second': '10.099', 'grad_norm': '14.567', 'counters/examples': 5504, 'counters/updates': 43}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 98% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 5632 examples: {'rewards_train/chosen': '-1.1822', 'rewards_train/rejected': '-1.6119', 'rewards_train/accuracies': '0.64844', 'rewards_train/margins': '0.42973', 'logps_train/rejected': '-109.69', 'logps_train/chosen': '-98.668', 'loss/train': '0.61801', 'examples_per_second': '7.3488', 'grad_norm': '15.85', 'counters/examples': 5632, 'counters/updates': 44}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 5760 examples: {'rewards_train/chosen': '-1.0094', 'rewards_train/rejected': '-1.5706', 'rewards_train/accuracies': '0.76562', 'rewards_train/margins': '0.56115', 'logps_train/rejected': '-142.9', 'logps_train/chosen': '-114.62', 'loss/train': '0.54425', 'examples_per_second': '8.398', 'grad_norm': '15.813', 'counters/examples': 5760, 'counters/updates': 45}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 5888 examples: {'rewards_train/chosen': '-0.94078', 'rewards_train/rejected': '-1.6693', 'rewards_train/accuracies': '0.78125', 'rewards_train/margins': '0.72857', 'logps_train/rejected': '-132.56', 'logps_train/chosen': '-111.89', 'loss/train': '0.48481', 'examples_per_second': '5.7479', 'grad_norm': '14.978', 'counters/examples': 5888, 'counters/updates': 46}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 96% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 6016 examples: {'rewards_train/chosen': '-1.431', 'rewards_train/rejected': '-2.3941', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.96307', 'logps_train/rejected': '-134.35', 'logps_train/chosen': '-100.42', 'loss/train': '0.49976', 'examples_per_second': '10.26', 'grad_norm': '15.957', 'counters/examples': 6016, 'counters/updates': 47}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 6144 examples: {'rewards_train/chosen': '-1.5894', 'rewards_train/rejected': '-2.5012', 'rewards_train/accuracies': '0.6875', 'rewards_train/margins': '0.91178', 'logps_train/rejected': '-133.91', 'logps_train/chosen': '-124.25', 'loss/train': '0.56822', 'examples_per_second': '9.6035', 'grad_norm': '20.551', 'counters/examples': 6144, 'counters/updates': 48}
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 98% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 6272 examples: {'rewards_train/chosen': '-0.78878', 'rewards_train/rejected': '-1.4158', 'rewards_train/accuracies': '0.77344', 'rewards_train/margins': '0.62706', 'logps_train/rejected': '-118.9', 'logps_train/chosen': '-97.957', 'loss/train': '0.50388', 'examples_per_second': '9.6856', 'grad_norm': '14.646', 'counters/examples': 6272, 'counters/updates': 49}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 6400 examples: {'rewards_train/chosen': '-1.645', 'rewards_train/rejected': '-2.6309', 'rewards_train/accuracies': '0.73438', 'rewards_train/margins': '0.98585', 'logps_train/rejected': '-141.15', 'logps_train/chosen': '-115.2', 'loss/train': '0.49044', 'examples_per_second': '8.2984', 'grad_norm': '16.59', 'counters/examples': 6400, 'counters/updates': 50}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 98% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 96% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 6528 examples: {'rewards_train/chosen': '-1.3039', 'rewards_train/rejected': '-2.1854', 'rewards_train/accuracies': '0.75781', 'rewards_train/margins': '0.88151', 'logps_train/rejected': '-148.63', 'logps_train/chosen': '-123.46', 'loss/train': '0.52585', 'examples_per_second': '9.1169', 'grad_norm': '17.444', 'counters/examples': 6528, 'counters/updates': 51}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81340.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81434.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81232.2 MB / 81920.0 MB
Train stats after 6656 examples: {'rewards_train/chosen': '-1.0601', 'rewards_train/rejected': '-1.7825', 'rewards_train/accuracies': '0.72656', 'rewards_train/margins': '0.7224', 'logps_train/rejected': '-156.75', 'logps_train/chosen': '-125.99', 'loss/train': '0.5117', 'examples_per_second': '7.8533', 'grad_norm': '16.763', 'counters/examples': 6656, 'counters/updates': 52}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 98% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 6784 examples: {'rewards_train/chosen': '-1.4867', 'rewards_train/rejected': '-2.4685', 'rewards_train/accuracies': '0.74219', 'rewards_train/margins': '0.98177', 'logps_train/rejected': '-160.05', 'logps_train/chosen': '-134.11', 'loss/train': '0.50773', 'examples_per_second': '6.937', 'grad_norm': '18.253', 'counters/examples': 6784, 'counters/updates': 53}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 6912 examples: {'rewards_train/chosen': '-1.1409', 'rewards_train/rejected': '-1.9003', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.75938', 'logps_train/rejected': '-142.89', 'logps_train/chosen': '-118.66', 'loss/train': '0.51216', 'examples_per_second': '6.8793', 'grad_norm': '16.171', 'counters/examples': 6912, 'counters/updates': 54}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 7040 examples: {'rewards_train/chosen': '-1.0837', 'rewards_train/rejected': '-1.946', 'rewards_train/accuracies': '0.77344', 'rewards_train/margins': '0.86228', 'logps_train/rejected': '-123.31', 'logps_train/chosen': '-117.37', 'loss/train': '0.48053', 'examples_per_second': '11.493', 'grad_norm': '15.529', 'counters/examples': 7040, 'counters/updates': 55}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 98% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81436.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 7168 examples: {'rewards_train/chosen': '-1.3316', 'rewards_train/rejected': '-2.4524', 'rewards_train/accuracies': '0.80469', 'rewards_train/margins': '1.1208', 'logps_train/rejected': '-140.34', 'logps_train/chosen': '-108.18', 'loss/train': '0.39956', 'examples_per_second': '11.356', 'grad_norm': '16.272', 'counters/examples': 7168, 'counters/updates': 56}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 7296 examples: {'rewards_train/chosen': '-2.522', 'rewards_train/rejected': '-3.8354', 'rewards_train/accuracies': '0.76562', 'rewards_train/margins': '1.3134', 'logps_train/rejected': '-169.77', 'logps_train/chosen': '-131.01', 'loss/train': '0.53027', 'examples_per_second': '5.9498', 'grad_norm': '20.971', 'counters/examples': 7296, 'counters/updates': 57}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 96% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 96% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 7424 examples: {'rewards_train/chosen': '-1.3468', 'rewards_train/rejected': '-2.1124', 'rewards_train/accuracies': '0.74219', 'rewards_train/margins': '0.76559', 'logps_train/rejected': '-143.35', 'logps_train/chosen': '-121.16', 'loss/train': '0.51743', 'examples_per_second': '6.6416', 'grad_norm': '16.172', 'counters/examples': 7424, 'counters/updates': 58}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 7552 examples: {'rewards_train/chosen': '-1.0211', 'rewards_train/rejected': '-2.0181', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.99703', 'logps_train/rejected': '-160.65', 'logps_train/chosen': '-106.06', 'loss/train': '0.45376', 'examples_per_second': '10.099', 'grad_norm': '15.089', 'counters/examples': 7552, 'counters/updates': 59}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 7680 examples: {'rewards_train/chosen': '-1.4662', 'rewards_train/rejected': '-2.7201', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '1.2538', 'logps_train/rejected': '-134.29', 'logps_train/chosen': '-108.23', 'loss/train': '0.42982', 'examples_per_second': '7.616', 'grad_norm': '16.444', 'counters/examples': 7680, 'counters/updates': 60}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 7808 examples: {'rewards_train/chosen': '-1.3602', 'rewards_train/rejected': '-2.236', 'rewards_train/accuracies': '0.75', 'rewards_train/margins': '0.87582', 'logps_train/rejected': '-118.89', 'logps_train/chosen': '-103.34', 'loss/train': '0.50005', 'examples_per_second': '6.1297', 'grad_norm': '18.754', 'counters/examples': 7808, 'counters/updates': 61}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 7936 examples: {'rewards_train/chosen': '-1.2564', 'rewards_train/rejected': '-2.1306', 'rewards_train/accuracies': '0.70312', 'rewards_train/margins': '0.87422', 'logps_train/rejected': '-136.86', 'logps_train/chosen': '-122.37', 'loss/train': '0.5265', 'examples_per_second': '8.3515', 'grad_norm': '17.481', 'counters/examples': 7936, 'counters/updates': 62}
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 0% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 0% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 0% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 98% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 8064 examples: {'rewards_train/chosen': '-1.0942', 'rewards_train/rejected': '-1.8093', 'rewards_train/accuracies': '0.75781', 'rewards_train/margins': '0.7151', 'logps_train/rejected': '-121.55', 'logps_train/chosen': '-99.128', 'loss/train': '0.51553', 'examples_per_second': '10.162', 'grad_norm': '13.385', 'counters/examples': 8064, 'counters/updates': 63}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 8192 examples: {'rewards_train/chosen': '-0.99465', 'rewards_train/rejected': '-1.834', 'rewards_train/accuracies': '0.78906', 'rewards_train/margins': '0.8393', 'logps_train/rejected': '-122.33', 'logps_train/chosen': '-106.8', 'loss/train': '0.47436', 'examples_per_second': '8.1551', 'grad_norm': '13.584', 'counters/examples': 8192, 'counters/updates': 64}
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 0% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 0% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 0% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 8320 examples: {'rewards_train/chosen': '-1.3614', 'rewards_train/rejected': '-2.54', 'rewards_train/accuracies': '0.79688', 'rewards_train/margins': '1.1786', 'logps_train/rejected': '-121.19', 'logps_train/chosen': '-106.14', 'loss/train': '0.43476', 'examples_per_second': '8.821', 'grad_norm': '14.145', 'counters/examples': 8320, 'counters/updates': 65}
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 8448 examples: {'rewards_train/chosen': '-2.0689', 'rewards_train/rejected': '-2.9688', 'rewards_train/accuracies': '0.64062', 'rewards_train/margins': '0.89989', 'logps_train/rejected': '-149.81', 'logps_train/chosen': '-129.45', 'loss/train': '0.58889', 'examples_per_second': '10.237', 'grad_norm': '24.014', 'counters/examples': 8448, 'counters/updates': 66}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 96% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 8576 examples: {'rewards_train/chosen': '-0.91046', 'rewards_train/rejected': '-1.9552', 'rewards_train/accuracies': '0.80469', 'rewards_train/margins': '1.0448', 'logps_train/rejected': '-137.39', 'logps_train/chosen': '-107.95', 'loss/train': '0.42478', 'examples_per_second': '7.931', 'grad_norm': '14.15', 'counters/examples': 8576, 'counters/updates': 67}
[GPU Monitor] GPU 0: 利用率 98% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 8704 examples: {'rewards_train/chosen': '-1.6374', 'rewards_train/rejected': '-2.7794', 'rewards_train/accuracies': '0.76562', 'rewards_train/margins': '1.142', 'logps_train/rejected': '-144.6', 'logps_train/chosen': '-121.84', 'loss/train': '0.4522', 'examples_per_second': '9.5787', 'grad_norm': '16.821', 'counters/examples': 8704, 'counters/updates': 68}
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 0% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 0% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 0% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 0% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 8832 examples: {'rewards_train/chosen': '-1.4604', 'rewards_train/rejected': '-2.7701', 'rewards_train/accuracies': '0.8125', 'rewards_train/margins': '1.3097', 'logps_train/rejected': '-130.64', 'logps_train/chosen': '-101.13', 'loss/train': '0.39321', 'examples_per_second': '9.0678', 'grad_norm': '13.808', 'counters/examples': 8832, 'counters/updates': 69}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 98% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 8960 examples: {'rewards_train/chosen': '-1.645', 'rewards_train/rejected': '-3.3628', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '1.7179', 'logps_train/rejected': '-148.61', 'logps_train/chosen': '-115.96', 'loss/train': '0.36249', 'examples_per_second': '7.8039', 'grad_norm': '16.801', 'counters/examples': 8960, 'counters/updates': 70}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 9088 examples: {'rewards_train/chosen': '-2.0219', 'rewards_train/rejected': '-3.3491', 'rewards_train/accuracies': '0.75781', 'rewards_train/margins': '1.3272', 'logps_train/rejected': '-171.51', 'logps_train/chosen': '-134.2', 'loss/train': '0.42406', 'examples_per_second': '9.5674', 'grad_norm': '17.047', 'counters/examples': 9088, 'counters/updates': 71}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 9216 examples: {'rewards_train/chosen': '-2.0012', 'rewards_train/rejected': '-3.4276', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '1.4265', 'logps_train/rejected': '-142.39', 'logps_train/chosen': '-116.57', 'loss/train': '0.4295', 'examples_per_second': '7.8561', 'grad_norm': '16.193', 'counters/examples': 9216, 'counters/updates': 72}
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 98% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 9344 examples: {'rewards_train/chosen': '-1.3546', 'rewards_train/rejected': '-2.5994', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '1.2449', 'logps_train/rejected': '-146.86', 'logps_train/chosen': '-119.42', 'loss/train': '0.39303', 'examples_per_second': '8.7726', 'grad_norm': '14.801', 'counters/examples': 9344, 'counters/updates': 73}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 99% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 99% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 9472 examples: {'rewards_train/chosen': '-2.3476', 'rewards_train/rejected': '-4.215', 'rewards_train/accuracies': '0.78125', 'rewards_train/margins': '1.8674', 'logps_train/rejected': '-172.55', 'logps_train/chosen': '-124.75', 'loss/train': '0.41339', 'examples_per_second': '8.3417', 'grad_norm': '18.28', 'counters/examples': 9472, 'counters/updates': 74}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 9600 examples: {'rewards_train/chosen': '-1.819', 'rewards_train/rejected': '-3.3058', 'rewards_train/accuracies': '0.80469', 'rewards_train/margins': '1.4868', 'logps_train/rejected': '-161.36', 'logps_train/chosen': '-122.99', 'loss/train': '0.41848', 'examples_per_second': '7.3616', 'grad_norm': '16.351', 'counters/examples': 9600, 'counters/updates': 75}
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 96% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 98% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 97% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 9728 examples: {'rewards_train/chosen': '-1.7451', 'rewards_train/rejected': '-3.1624', 'rewards_train/accuracies': '0.82031', 'rewards_train/margins': '1.4173', 'logps_train/rejected': '-135.06', 'logps_train/chosen': '-118.41', 'loss/train': '0.39734', 'examples_per_second': '9.4816', 'grad_norm': '15.533', 'counters/examples': 9728, 'counters/updates': 76}
[GPU Monitor] GPU 0: 利用率 97% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 97% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 9856 examples: {'rewards_train/chosen': '-1.7861', 'rewards_train/rejected': '-3.0307', 'rewards_train/accuracies': '0.78125', 'rewards_train/margins': '1.2446', 'logps_train/rejected': '-155.9', 'logps_train/chosen': '-123.98', 'loss/train': '0.43706', 'examples_per_second': '6.4598', 'grad_norm': '16.244', 'counters/examples': 9856, 'counters/updates': 77}
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 97% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 100% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 99% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 99% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Train stats after 9984 examples: {'rewards_train/chosen': '-2.4452', 'rewards_train/rejected': '-3.9825', 'rewards_train/accuracies': '0.79688', 'rewards_train/margins': '1.5372', 'logps_train/rejected': '-151.11', 'logps_train/chosen': '-115.31', 'loss/train': '0.44194', 'examples_per_second': '10.065', 'grad_norm': '18.461', 'counters/examples': 9984, 'counters/updates': 78}
Finished generating 1 epochs on train split
[GPU Monitor] GPU 0: 利用率 9% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 8% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Writing checkpoint to /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/direct-preference-optimization-main/.cache/root/llama3-8b-sftdpo-warmup-hh-helpful-dpo/LATEST/policy.pt ...
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 10% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Writing checkpoint to /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/direct-preference-optimization-main/.cache/root/llama3-8b-sftdpo-warmup-hh-helpful-dpo/LATEST/optimizer.pt ...
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
[GPU Monitor] GPU 0: 利用率 0% | 内存使用 81758.2 MB / 81920.0 MB
[GPU Monitor] GPU 1: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 2: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 3: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 4: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 5: 利用率 100% | 内存使用 81852.2 MB / 81920.0 MB
[GPU Monitor] GPU 6: 利用率 100% | 内存使用 81854.2 MB / 81920.0 MB
[GPU Monitor] GPU 7: 利用率 100% | 内存使用 81650.2 MB / 81920.0 MB
Writing checkpoint to /fs-computility/llmit_d/shared/zhangchi/wjc/DPO/direct-preference-optimization-main/.cache/root/llama3-8b-sftdpo-warmup-hh-helpful-dpo/LATEST/scheduler.pt ...
t-20250727224157-jr2mh-worker-0:6954:6954 [3] NCCL INFO cudaDriverVersion 12040
t-20250727224157-jr2mh-worker-0:6954:6954 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:6954:6954 [3] NCCL INFO Bootstrap : Using eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:6954:6954 [3] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:6954:6954 [3] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
t-20250727224157-jr2mh-worker-0:6954:6954 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:6954:6954 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
t-20250727224157-jr2mh-worker-0:6954:6954 [3] NCCL INFO Comm config Blocking set to 1
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO P2P plugin IBext
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_2:1/RoCE [2]mlx5_3:1/RoCE [3]mlx5_4:1/RoCE [RO]; OOB eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Using non-device net plugin version 0
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Using network IBext
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO ncclCommInitRank comm 0x113f57a0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 6a000 commId 0xfc447bdf9e87bd95 - Init START
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO NVLS multicast support is not available on dev 3
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO comm 0x113f57a0 rank 3 nRanks 8 nNodes 1 localRanks 8 localRank 3 MNNVL 0
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO P2P Chunksize set to 524288
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 02/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 03/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 04/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 05/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 06/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 07/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 08/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 09/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 10/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 11/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 12/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 13/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 14/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 15/0 : 3[3] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Connected all rings
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 08/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 12/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 14/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Channel 15/0 : 3[3] -> 2[2] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO Connected all trees
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO 16 coll channels, 16 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.
t-20250727224157-jr2mh-worker-0:6954:7885 [3] NCCL INFO ncclCommInitRank comm 0x113f57a0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 6a000 commId 0xfc447bdf9e87bd95 - Init COMPLETE
t-20250727224157-jr2mh-worker-0:7563:7563 [7] NCCL INFO cudaDriverVersion 12040
t-20250727224157-jr2mh-worker-0:7563:7563 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:7563:7563 [7] NCCL INFO Bootstrap : Using eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:7563:7563 [7] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:7563:7563 [7] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
t-20250727224157-jr2mh-worker-0:7563:7563 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:7563:7563 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
t-20250727224157-jr2mh-worker-0:7563:7563 [7] NCCL INFO Comm config Blocking set to 1
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO P2P plugin IBext
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_2:1/RoCE [2]mlx5_3:1/RoCE [3]mlx5_4:1/RoCE [RO]; OOB eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Using non-device net plugin version 0
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Using network IBext
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO ncclCommInitRank comm 0x12b3b7b0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId c7000 commId 0xfc447bdf9e87bd95 - Init START
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,00000000,ffffffff,00000000
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO NVLS multicast support is not available on dev 7
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO comm 0x12b3b7b0 rank 7 nRanks 8 nNodes 1 localRanks 8 localRank 7 MNNVL 0
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO P2P Chunksize set to 524288
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 00/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 01/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 02/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 03/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 04/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 05/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 06/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 07/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 08/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 09/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 10/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 11/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 12/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 13/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 14/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 15/0 : 7[7] -> 0[0] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Connected all rings
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 01/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 02/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 03/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 04/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 05/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 06/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 07/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 08/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 09/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 10/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 11/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 12/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 13/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 14/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Channel 15/0 : 7[7] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO Connected all trees
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO 16 coll channels, 16 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.
t-20250727224157-jr2mh-worker-0:7563:7880 [7] NCCL INFO ncclCommInitRank comm 0x12b3b7b0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId c7000 commId 0xfc447bdf9e87bd95 - Init COMPLETE
t-20250727224157-jr2mh-worker-0:7105:7105 [4] NCCL INFO cudaDriverVersion 12040
t-20250727224157-jr2mh-worker-0:7105:7105 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:7105:7105 [4] NCCL INFO Bootstrap : Using eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:7105:7105 [4] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:7105:7105 [4] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
t-20250727224157-jr2mh-worker-0:7105:7105 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:7105:7105 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
t-20250727224157-jr2mh-worker-0:7105:7105 [4] NCCL INFO Comm config Blocking set to 1
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO P2P plugin IBext
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_2:1/RoCE [2]mlx5_3:1/RoCE [3]mlx5_4:1/RoCE [RO]; OOB eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Using non-device net plugin version 0
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Using network IBext
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO ncclCommInitRank comm 0xdeb18a0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 9d000 commId 0xfc447bdf9e87bd95 - Init START
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,00000000,ffffffff,00000000
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO NVLS multicast support is not available on dev 4
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO comm 0xdeb18a0 rank 4 nRanks 8 nNodes 1 localRanks 8 localRank 4 MNNVL 0
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO P2P Chunksize set to 524288
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 02/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 03/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 04/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 05/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 06/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 07/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 08/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 09/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 10/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 11/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 12/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 13/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 14/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 15/0 : 4[4] -> 5[5] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Connected all rings
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 02/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 03/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 04/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 05/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 06/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 07/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 08/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 09/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 10/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 11/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 12/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 13/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 14/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Channel 15/0 : 4[4] -> 3[3] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO Connected all trees
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO 16 coll channels, 16 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.
t-20250727224157-jr2mh-worker-0:7105:7881 [4] NCCL INFO ncclCommInitRank comm 0xdeb18a0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 9d000 commId 0xfc447bdf9e87bd95 - Init COMPLETE
t-20250727224157-jr2mh-worker-0:7260:7260 [5] NCCL INFO cudaDriverVersion 12040
t-20250727224157-jr2mh-worker-0:7260:7260 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:7260:7260 [5] NCCL INFO Bootstrap : Using eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:7260:7260 [5] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:7260:7260 [5] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
t-20250727224157-jr2mh-worker-0:7260:7260 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
t-20250727224157-jr2mh-worker-0:7260:7260 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
t-20250727224157-jr2mh-worker-0:7260:7260 [5] NCCL INFO Comm config Blocking set to 1
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO P2P plugin IBext
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_2:1/RoCE [2]mlx5_3:1/RoCE [3]mlx5_4:1/RoCE [RO]; OOB eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Using non-device net plugin version 0
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Using network IBext
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO ncclCommInitRank comm 0x1080e3d0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId a2000 commId 0xfc447bdf9e87bd95 - Init START
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,00000000,ffffffff,00000000
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO NVLS multicast support is not available on dev 5
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO comm 0x1080e3d0 rank 5 nRanks 8 nNodes 1 localRanks 8 localRank 5 MNNVL 0
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO P2P Chunksize set to 524288
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 02/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 03/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 04/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 05/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 06/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 07/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 08/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 09/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 10/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 11/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 12/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 13/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 14/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 15/0 : 5[5] -> 6[6] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Connected all rings
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 02/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 03/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 04/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 05/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 06/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 07/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 08/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 09/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 10/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 11/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 12/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 13/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 14/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Channel 15/0 : 5[5] -> 4[4] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO Connected all trees
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO 16 coll channels, 16 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.
t-20250727224157-jr2mh-worker-0:7260:7886 [5] NCCL INFO ncclCommInitRank comm 0x1080e3d0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId a2000 commId 0xfc447bdf9e87bd95 - Init COMPLETE
t-20250727224157-jr2mh-worker-0:6638:6638 [0] NCCL INFO Comm config Blocking set to 1
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Plugin Path : /usr/local/nccl-rdma-sharp-plugins/lib/libnccl-net.so
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO P2P plugin IBext
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth1
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO NCCL_IB_PCI_RELAXED_ORDERING set by environment to 1.
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/RoCE [1]mlx5_2:1/RoCE [2]mlx5_3:1/RoCE [3]mlx5_4:1/RoCE [RO]; OOB eth1:172.30.62.202<0>
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Using non-device net plugin version 0
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Using network IBext
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO ncclCommInitRank comm 0x10472200 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 40000 commId 0xfc447bdf9e87bd95 - Init START
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO NVLS multicast support is not available on dev 0
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO comm 0x10472200 rank 0 nRanks 8 nNodes 1 localRanks 8 localRank 0 MNNVL 0
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 00/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 01/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 02/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 03/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 04/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 05/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 06/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 07/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 08/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 09/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 10/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 11/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 12/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 13/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 14/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 15/16 :    0   1   2   3   4   5   6   7
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO P2P Chunksize set to 524288
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/CUMEM/read
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Connected all rings
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO Connected all trees
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO 16 coll channels, 16 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.
t-20250727224157-jr2mh-worker-0:6638:7879 [0] NCCL INFO ncclCommInitRank comm 0x10472200 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 40000 commId 0xfc447bdf9e87bd95 - Init COMPLETE
