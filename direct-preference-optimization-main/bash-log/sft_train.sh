# export CUDA_VISIBLE_DEVICES=1

# # ç”¨ (â€¦â€‹) å¼€å¯å­ shellï¼Œè®­ç»ƒè·‘å®Œä¹‹åŽæ‰“å°ä¸€æ¡æç¤º  
# ( \
#   python -u train.py \
#     model=qwen2.5-7B \
#     datasets=[helpful-base] \
#     loss=sft \
#     exp_name=anthropic_sft_qwen2.5-7B \
#     gradient_accumulation_steps=2 \
#     batch_size=8 \
#     eval_batch_size=4 \
#     trainer=FSDPTrainer \
#     sample_during_eval=false \
#     model.fsdp_policy_mp=bfloat16 \
#     > sft_train_qwen_7B.log 2>&1 \
#   && echo "[$(date +'%Y-%m-%d\ %H:%M:%S')] ðŸŽ‰ è®­ç»ƒå®Œæˆï¼çœ‹è¿™é‡Œ 11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111" \
# ) &

# # è¿™æ—¶ä½ ä¼šç«‹å³çœ‹åˆ°ï¼š
# # [1] 12345
# #   â†‘ job number   â†‘ PID

export CUDA_VISIBLE_DEVICES=0,1,2,3

# torchrun \
#   --nproc_per_node=4 \               # 2 ä¸ªè¿›ç¨‹ â†’ 2 å¼ å¡
#   --master_addr=127.0.0.1 \          # rendezvous åœ°å€
#   --master_port=29500 \              # rendezvous ç«¯å£ï¼Œå¿…é¡»æ‰€æœ‰è¿›ç¨‹ä¸€è‡´
#   python train.py \
#     model=qwen3-1.7b \
#     datasets=[helpful-base] \
#     loss=sft \
#     exp_name=qwen3-1.7b-sft \
#     gradient_accumulation_steps=4 \
#     batch_size=16 \
#     eval_batch_size=8 \
#     trainer=FSDPTrainer \
#     sample_during_eval=false \
#     model.fsdp_policy_mp=bfloat16 \
#     > sft_train_qwen3-1.7b.log 2>&1 \
#     && echo "[$(date +'%Y-%m-%d\ %H:%M:%S')] ðŸŽ‰ è®­ç»ƒå®Œæˆï¼çœ‹è¿™é‡Œ 11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111"  &



# torchrun \
#     --nproc_per_node=4 \
#     --master_addr=127.0.0.1 \
#     --master_port=29501 \



    # python train.py \
    # model=qwen3-1.7b-base \
    # datasets=["/fs-computility/llmit_d/shared/zhangchi/wjc/DPO/dataset/temp/train.jsonl"] \
    # loss=sft \
    # exp_name=qwen3-1.7b-sft-test \
    # gradient_accumulation_steps=4 \
    # batch_size=16 \
    # eval_batch_size=8 \
    # trainer=FSDPTrainer \
    # sample_during_eval=false \
    # model.fsdp_policy_mp=bfloat16 \
    # > sft_train_qwen3-1.7b.log 2>&1 \


    python train.py \
  exp_name=dpo_qwen3_1.7b_test \
  local_dirs="['/fs-computility/llmit_d/shared/zhangchi/wjc/DPO/direct-preference-optimization-main/.cache']" \
  model=qwen3-1.7b-base \
  model.name_or_path=/fs-computility/llmit_d/shared/zhangchi/wjc/DPO/workspace/dpo-qwen3-1.7B \
  model.tokenizer_name_or_path=/fs-computility/llmit_d/shared/zhangchi/wjc/DPO/workspace/dpo-qwen3-1.7B \
  model.block_name=Qwen3DecoderLayer \
  model.policy_dtype=float32 \
  model.reference_dtype=float16 \
  trainer=FSDPTrainer \
  loss.name=sft \
  datasets="['/fs-computility/llmit_d/shared/zhangchi/wjc/DPO/dataset/temp/train.jsonl']" \
  batch_size=16 \
  eval_batch_size=8 \
  lr=1e-5 \
  n_epochs=3 \
  gradient_accumulation_steps=4 \
